{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AudioTagging.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKlmABPy5ZEU"
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive/')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PZFDCQ2s5ZpN"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7L7GMTAdksN"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import librosa\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,Dropout,Activation,Flatten\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers, callbacks"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDD5lYIbd5pK"
      },
      "source": [
        "Defining some constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGlcFA0zdOtw"
      },
      "source": [
        "Fs = 16000\n",
        "n_mfcc  = 20\n",
        "Data_path = '/content/drive/MyDrive/EE603-Project/files'\n",
        "Labels_csv_path = '/content/drive/MyDrive/EE603-Project/TrainLabels.csv'"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "DdUWR1MyhJGk",
        "outputId": "4f77caac-7a50-469f-9534-507c8f591337"
      },
      "source": [
        "labels = pd.read_csv(Labels_csv_path)\n",
        "labels.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>onset</th>\n",
              "      <th>offset</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>musph0_.wav</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>3.8219</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>musph0_.wav</td>\n",
              "      <td>3.8219</td>\n",
              "      <td>6.8219</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>musph0_.wav</td>\n",
              "      <td>6.8219</td>\n",
              "      <td>7.4842</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>musph0_.wav</td>\n",
              "      <td>7.4842</td>\n",
              "      <td>8.4842</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>musph0_.wav</td>\n",
              "      <td>8.4842</td>\n",
              "      <td>10.0000</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      filename   onset   offset    class\n",
              "0  musph0_.wav  0.0000   3.8219  silence\n",
              "1  musph0_.wav  3.8219   6.8219    music\n",
              "2  musph0_.wav  6.8219   7.4842  silence\n",
              "3  musph0_.wav  7.4842   8.4842   speech\n",
              "4  musph0_.wav  8.4842  10.0000  silence"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rnst92l8fE8O"
      },
      "source": [
        "Extracting MFCC Feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsDLftlmemJv"
      },
      "source": [
        "def extract_mfcc(f,on,of):\n",
        "  '''\n",
        "  f: it is the path to the file whose mfcc is to be extracted\n",
        "  on and of: onset time and offset time of feature extraction\n",
        "  '''\n",
        "  a,_ = librosa.load(f,sr = Fs)\n",
        "  d = a[int(on*Fs):int(of*Fs)]\n",
        "  mfccs = librosa.feature.mfcc(y=d, sr=Fs, n_mfcc=n_mfcc)\n",
        "  \n",
        "  return np.mean(mfccs.T,axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18zyoYK1gqfE"
      },
      "source": [
        "Checking extract_mfcc:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tC0j0RINgoUJ",
        "outputId": "f439ba12-f0d8-4da2-ad0e-52861a9140a5"
      },
      "source": [
        "f = '/content/drive/MyDrive/EE603-Project/files/musph0_.wav'\n",
        "for i in range(4):\n",
        "  on = labels['onset'][i]\n",
        "  off = labels['offset'][i]\n",
        "  print(extract_mfcc(f,on,off))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-1131.371     0.        0.        0.        0.        0.        0.\n",
            "     0.        0.        0.        0.        0.        0.        0.\n",
            "     0.        0.        0.        0.        0.        0.   ]\n",
            "[-269.5914      70.749886     2.674555   -25.777128   -45.74757\n",
            "    5.9979787   -9.86615    -35.33644    -21.507563    -3.6931431\n",
            "    1.5742964    9.805985    -8.926946     3.8702295  -25.474064\n",
            "   11.410781   -14.259767   -13.246624    -9.13262    -12.650727 ]\n",
            "[-1131.3708     0.         0.         0.         0.         0.\n",
            "     0.         0.         0.         0.         0.         0.\n",
            "     0.         0.         0.         0.         0.         0.\n",
            "     0.         0.    ]\n",
            "[-2.0918173e+02  8.0522346e+01 -4.8038278e+00  3.7486053e+01\n",
            "  1.4823071e+01  6.4469771e+00 -9.8323479e+00 -1.5065784e+00\n",
            " -3.7379432e-01 -1.2389159e+00 -1.5326183e+01 -6.7483759e-01\n",
            " -9.4394522e+00 -1.4500582e-01 -1.1870794e+01 -6.0792632e+00\n",
            " -9.9727039e+00 -3.7979274e+00 -1.1407868e+01 -3.6513884e+00]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_oyBoe0jEqT"
      },
      "source": [
        "Extracting Features and storing in a list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "M_rwuiQSlFEi",
        "outputId": "4b8e548a-53a6-4edf-ed3f-2ac002a8b28a"
      },
      "source": [
        "f = os.path.join(os.path.abspath(Data_path),str('musph0_.wav'))\n",
        "f"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/EE603-Project/files/musph0_.wav'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sTu0p9KCh_dH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5f76512-4ac8-4185-f1d3-331152cd3445"
      },
      "source": [
        "features = []\n",
        "for id, ro in tqdm(labels.iterrows()):\n",
        "  f = os.path.join(os.path.abspath(Data_path),str(ro['filename']))\n",
        "  on = ro['onset']\n",
        "  of = ro['offset']\n",
        "  clas = ro['class']\n",
        "  features.append([extract_mfcc(f,on,of),clas])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "21it [00:01, 19.71it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=402\n",
            "  n_fft, y.shape[-1]\n",
            "36it [00:01, 19.97it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=411\n",
            "  n_fft, y.shape[-1]\n",
            "46it [00:02, 19.51it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=664\n",
            "  n_fft, y.shape[-1]\n",
            "50it [00:02, 18.59it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1940\n",
            "  n_fft, y.shape[-1]\n",
            "159it [00:07, 20.20it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1378\n",
            "  n_fft, y.shape[-1]\n",
            "/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=893\n",
            "  n_fft, y.shape[-1]\n",
            "179it [00:08, 21.53it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=801\n",
            "  n_fft, y.shape[-1]\n",
            "228it [00:11, 20.89it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=487\n",
            "  n_fft, y.shape[-1]\n",
            "238it [00:11, 20.47it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=709\n",
            "  n_fft, y.shape[-1]\n",
            "298it [00:14, 21.34it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1739\n",
            "  n_fft, y.shape[-1]\n",
            "308it [00:15, 21.49it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1053\n",
            "  n_fft, y.shape[-1]\n",
            "346it [00:17, 17.88it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1109\n",
            "  n_fft, y.shape[-1]\n",
            "366it [00:18, 20.00it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1317\n",
            "  n_fft, y.shape[-1]\n",
            "406it [00:20, 19.50it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=520\n",
            "  n_fft, y.shape[-1]\n",
            "431it [00:21, 19.95it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=763\n",
            "  n_fft, y.shape[-1]\n",
            "466it [00:23, 20.84it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1730\n",
            "  n_fft, y.shape[-1]\n",
            "471it [00:23, 20.63it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1957\n",
            "  n_fft, y.shape[-1]\n",
            "629it [00:31, 21.03it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=803\n",
            "  n_fft, y.shape[-1]\n",
            "673it [00:33, 20.63it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=418\n",
            "  n_fft, y.shape[-1]\n",
            "682it [00:33, 20.69it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1873\n",
            "  n_fft, y.shape[-1]\n",
            "702it [00:34, 22.11it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1323\n",
            "  n_fft, y.shape[-1]\n",
            "711it [00:35, 20.19it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1810\n",
            "  n_fft, y.shape[-1]\n",
            "755it [00:37, 21.54it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=824\n",
            "  n_fft, y.shape[-1]\n",
            "785it [00:38, 22.09it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=548\n",
            "  n_fft, y.shape[-1]\n",
            "795it [00:39, 21.64it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=467\n",
            "  n_fft, y.shape[-1]\n",
            "810it [00:39, 22.11it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=466\n",
            "  n_fft, y.shape[-1]\n",
            "820it [00:40, 19.69it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=901\n",
            "  n_fft, y.shape[-1]\n",
            "859it [00:42, 21.33it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1247\n",
            "  n_fft, y.shape[-1]\n",
            "879it [00:43, 21.84it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1813\n",
            "  n_fft, y.shape[-1]\n",
            "906it [00:44, 19.39it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1673\n",
            "  n_fft, y.shape[-1]\n",
            "921it [00:45, 20.96it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1248\n",
            "  n_fft, y.shape[-1]\n",
            "926it [00:45, 21.02it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1331\n",
            "  n_fft, y.shape[-1]\n",
            "954it [00:46, 18.97it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=722\n",
            "  n_fft, y.shape[-1]\n",
            "969it [00:47, 19.59it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1076\n",
            "  n_fft, y.shape[-1]\n",
            "979it [00:48, 18.46it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=868\n",
            "  n_fft, y.shape[-1]\n",
            "993it [00:48, 20.38it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=730\n",
            "  n_fft, y.shape[-1]\n",
            "1003it [00:49, 20.58it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1659\n",
            "  n_fft, y.shape[-1]\n",
            "1041it [00:51, 18.27it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1496\n",
            "  n_fft, y.shape[-1]\n",
            "1065it [00:52, 19.64it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1886\n",
            "  n_fft, y.shape[-1]\n",
            "1149it [00:56, 21.01it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=573\n",
            "  n_fft, y.shape[-1]\n",
            "1154it [00:56, 21.45it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=421\n",
            "  n_fft, y.shape[-1]\n",
            "1169it [00:57, 21.42it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1821\n",
            "  n_fft, y.shape[-1]\n",
            "1189it [00:58, 22.39it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1239\n",
            "  n_fft, y.shape[-1]\n",
            "1209it [00:59, 21.79it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1938\n",
            "  n_fft, y.shape[-1]\n",
            "1214it [00:59, 20.83it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=937\n",
            "  n_fft, y.shape[-1]\n",
            "1244it [01:00, 22.01it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=674\n",
            "  n_fft, y.shape[-1]\n",
            "1308it [01:03, 21.48it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=855\n",
            "  n_fft, y.shape[-1]\n",
            "1356it [01:06, 18.41it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1557\n",
            "  n_fft, y.shape[-1]\n",
            "1366it [01:06, 20.07it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1573\n",
            "  n_fft, y.shape[-1]\n",
            "1376it [01:07, 20.91it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1732\n",
            "  n_fft, y.shape[-1]\n",
            "1381it [01:07, 19.84it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=629\n",
            "  n_fft, y.shape[-1]\n",
            "1391it [01:07, 20.72it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=918\n",
            "  n_fft, y.shape[-1]\n",
            "1429it [01:09, 20.52it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=1311\n",
            "  n_fft, y.shape[-1]\n",
            "1434it [01:09, 20.46it/s]/usr/local/lib/python3.7/dist-packages/librosa/core/spectrum.py:224: UserWarning: n_fft=2048 is too small for input signal of length=953\n",
            "  n_fft, y.shape[-1]\n",
            "1453it [01:10, 20.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5uGygLem7Og"
      },
      "source": [
        "Storing features in the form of dataframe for ease of training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2y3Bp6lumvaH"
      },
      "source": [
        "df = pd.DataFrame(features,columns=['mfccs','class'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5R_eoErynrOc",
        "outputId": "17b0186b-d28b-4db2-afc3-949ad1ddb2b4"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mfccs</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1448</th>\n",
              "      <td>[-1131.371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1449</th>\n",
              "      <td>[-7.95147, 70.178665, 4.8991804, 25.28807, 6.5...</td>\n",
              "      <td>music</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1450</th>\n",
              "      <td>[-939.08984, -1.9651121e-05, -6.1828e-06, 4.85...</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1451</th>\n",
              "      <td>[-157.78967, 94.30114, -17.505339, 31.592728, ...</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>[-1131.3708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...</td>\n",
              "      <td>silence</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  mfccs    class\n",
              "1448  [-1131.371, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,...  silence\n",
              "1449  [-7.95147, 70.178665, 4.8991804, 25.28807, 6.5...    music\n",
              "1450  [-939.08984, -1.9651121e-05, -6.1828e-06, 4.85...  silence\n",
              "1451  [-157.78967, 94.30114, -17.505339, 31.592728, ...   speech\n",
              "1452  [-1131.3708, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0...  silence"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsPgrdlPoUOw"
      },
      "source": [
        "Final processing for training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljpUt_gUnw21",
        "outputId": "56f8ba92-66b7-4981-d45d-cef2fe148428"
      },
      "source": [
        "X = np.array(df['mfccs'].tolist())\n",
        "Y = np.array(df['class'].tolist())\n",
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1453, 20)\n",
            "(1453,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kX-c4YlUo9iP"
      },
      "source": [
        "Onehot encoding the labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fVufbrgovfE"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "le=LabelEncoder()\n",
        "Y = to_categorical(le.fit_transform(Y))"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95vGuCKYpqI1"
      },
      "source": [
        "Train-Test Split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Czf8vkY_plXD"
      },
      "source": [
        "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.25,random_state=42)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MNGJ_GgWq9zx"
      },
      "source": [
        "Modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NIa4NOHrmJF",
        "outputId": "c2bfa31c-d580-46bf-9924-b692ba4d50f2"
      },
      "source": [
        "input_shape = [X_train.shape[1]]\n",
        "input_shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[20]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1jpYFfKG4cr"
      },
      "source": [
        "Model Architechture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMdrBireJ4m_"
      },
      "source": [
        "def model():\n",
        "\n",
        "  model = keras.Sequential(name=\"My_sequential\")\n",
        "\n",
        "\n",
        "  model.add(Dense(64,input_shape=input_shape))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "  model.add(Dense(128))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "  model.add(Dense(64))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  model.add(Dense(32))\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "  model.add(Dense(3))\n",
        "  model.add(Activation('softmax'))\n",
        "  \n",
        "  opt = keras.optimizers.Adam()\n",
        "  model.compile(loss='categorical_crossentropy',metrics=['accuracy'],optimizer=opt) \n",
        "\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSS9cII0K5UF"
      },
      "source": [
        "Model = model()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LE8Ab6mK91x",
        "outputId": "8d66b66b-1644-4a6a-ef12-45c03e09e751"
      },
      "source": [
        "Model.summary()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"My_sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                1344      \n",
            "                                                                 \n",
            " activation (Activation)     (None, 64)                0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 128)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 64)                0         \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 32)                0         \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 3)                 99        \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 3)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,099\n",
            "Trainable params: 20,099\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qv49Kki5LKYr",
        "outputId": "de068c39-f648-40dc-ecbd-efeb7780f7dc"
      },
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "checkpoint_path = '/content/drive/MyDrive/EE603-Project/model_saved'\n",
        "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
        "\n",
        "# Creating a callback that saves the model's weights\n",
        "cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                 save_weights_only=True,\n",
        "                                                 verbose=1)\n",
        "\n",
        "Model.fit(X_train, Y_train, batch_size=16, epochs=50, validation_data=(X_test, Y_test), callbacks=[cp_callback], verbose=1)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "69/69 [==============================] - ETA: 0s - loss: 13.3311 - accuracy: 0.6566\n",
            "Epoch 00001: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 2s 11ms/step - loss: 13.3311 - accuracy: 0.6566 - val_loss: 0.1891 - val_accuracy: 0.9505\n",
            "Epoch 2/50\n",
            "49/69 [====================>.........] - ETA: 0s - loss: 2.5718 - accuracy: 0.7934\n",
            "Epoch 00002: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 2.3575 - accuracy: 0.8090 - val_loss: 0.1173 - val_accuracy: 0.9725\n",
            "Epoch 3/50\n",
            "51/69 [=====================>........] - ETA: 0s - loss: 1.3070 - accuracy: 0.8456\n",
            "Epoch 00003: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 1.1815 - accuracy: 0.8531 - val_loss: 0.0763 - val_accuracy: 0.9808\n",
            "Epoch 4/50\n",
            "66/69 [===========================>..] - ETA: 0s - loss: 0.8402 - accuracy: 0.8778\n",
            "Epoch 00004: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.8423 - accuracy: 0.8742 - val_loss: 0.0668 - val_accuracy: 0.9780\n",
            "Epoch 5/50\n",
            "67/69 [============================>.] - ETA: 0s - loss: 0.5397 - accuracy: 0.9095\n",
            "Epoch 00005: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5313 - accuracy: 0.9109 - val_loss: 0.0522 - val_accuracy: 0.9808\n",
            "Epoch 6/50\n",
            "66/69 [===========================>..] - ETA: 0s - loss: 0.5217 - accuracy: 0.9110\n",
            "Epoch 00006: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.5085 - accuracy: 0.9118 - val_loss: 0.0404 - val_accuracy: 0.9863\n",
            "Epoch 7/50\n",
            "49/69 [====================>.........] - ETA: 0s - loss: 0.5612 - accuracy: 0.9171\n",
            "Epoch 00007: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.5273 - accuracy: 0.9155 - val_loss: 0.0715 - val_accuracy: 0.9863\n",
            "Epoch 8/50\n",
            "48/69 [===================>..........] - ETA: 0s - loss: 0.3613 - accuracy: 0.9362\n",
            "Epoch 00008: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3256 - accuracy: 0.9376 - val_loss: 0.0589 - val_accuracy: 0.9863\n",
            "Epoch 9/50\n",
            "48/69 [===================>..........] - ETA: 0s - loss: 0.2222 - accuracy: 0.9427\n",
            "Epoch 00009: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.2600 - accuracy: 0.9366 - val_loss: 0.0264 - val_accuracy: 0.9890\n",
            "Epoch 10/50\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.2488 - accuracy: 0.9431\n",
            "Epoch 00010: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.2488 - accuracy: 0.9431 - val_loss: 0.0216 - val_accuracy: 0.9890\n",
            "Epoch 11/50\n",
            "66/69 [===========================>..] - ETA: 0s - loss: 0.3345 - accuracy: 0.9545\n",
            "Epoch 00011: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.3244 - accuracy: 0.9559 - val_loss: 0.0121 - val_accuracy: 0.9918\n",
            "Epoch 12/50\n",
            "64/69 [==========================>...] - ETA: 0s - loss: 0.1416 - accuracy: 0.9658\n",
            "Epoch 00012: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1473 - accuracy: 0.9614 - val_loss: 0.0122 - val_accuracy: 0.9918\n",
            "Epoch 13/50\n",
            "51/69 [=====================>........] - ETA: 0s - loss: 0.0985 - accuracy: 0.9706\n",
            "Epoch 00013: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9660 - val_loss: 0.0093 - val_accuracy: 0.9945\n",
            "Epoch 14/50\n",
            "64/69 [==========================>...] - ETA: 0s - loss: 0.1408 - accuracy: 0.9727\n",
            "Epoch 00014: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.9734 - val_loss: 0.0120 - val_accuracy: 0.9918\n",
            "Epoch 15/50\n",
            "45/69 [==================>...........] - ETA: 0s - loss: 0.1662 - accuracy: 0.9736\n",
            "Epoch 00015: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1615 - accuracy: 0.9761 - val_loss: 0.0103 - val_accuracy: 0.9918\n",
            "Epoch 16/50\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.1534 - accuracy: 0.9780\n",
            "Epoch 00016: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.1534 - accuracy: 0.9780 - val_loss: 0.0087 - val_accuracy: 0.9973\n",
            "Epoch 17/50\n",
            "60/69 [=========================>....] - ETA: 0s - loss: 0.0909 - accuracy: 0.9740\n",
            "Epoch 00017: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0814 - accuracy: 0.9761 - val_loss: 0.0077 - val_accuracy: 0.9973\n",
            "Epoch 18/50\n",
            "49/69 [====================>.........] - ETA: 0s - loss: 0.0895 - accuracy: 0.9745\n",
            "Epoch 00018: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0964 - accuracy: 0.9734 - val_loss: 0.0071 - val_accuracy: 0.9973\n",
            "Epoch 19/50\n",
            "65/69 [===========================>..] - ETA: 0s - loss: 0.1047 - accuracy: 0.9808\n",
            "Epoch 00019: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.1052 - accuracy: 0.9789 - val_loss: 0.0068 - val_accuracy: 0.9973\n",
            "Epoch 20/50\n",
            "66/69 [===========================>..] - ETA: 0s - loss: 0.0571 - accuracy: 0.9792\n",
            "Epoch 00020: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0571 - accuracy: 0.9789 - val_loss: 0.0060 - val_accuracy: 0.9973\n",
            "Epoch 21/50\n",
            "68/69 [============================>.] - ETA: 0s - loss: 0.0696 - accuracy: 0.9835\n",
            "Epoch 00021: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0695 - accuracy: 0.9835 - val_loss: 0.0074 - val_accuracy: 0.9973\n",
            "Epoch 22/50\n",
            "47/69 [===================>..........] - ETA: 0s - loss: 0.1290 - accuracy: 0.9787\n",
            "Epoch 00022: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.9770 - val_loss: 0.0062 - val_accuracy: 0.9973\n",
            "Epoch 23/50\n",
            "67/69 [============================>.] - ETA: 0s - loss: 0.0787 - accuracy: 0.9823\n",
            "Epoch 00023: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9826 - val_loss: 0.0063 - val_accuracy: 0.9973\n",
            "Epoch 24/50\n",
            "67/69 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9785\n",
            "Epoch 00024: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0956 - accuracy: 0.9780 - val_loss: 0.0052 - val_accuracy: 0.9973\n",
            "Epoch 25/50\n",
            "68/69 [============================>.] - ETA: 0s - loss: 0.0771 - accuracy: 0.9844\n",
            "Epoch 00025: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0770 - accuracy: 0.9844 - val_loss: 0.0051 - val_accuracy: 0.9973\n",
            "Epoch 26/50\n",
            "63/69 [==========================>...] - ETA: 0s - loss: 0.0751 - accuracy: 0.9851\n",
            "Epoch 00026: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0707 - accuracy: 0.9862 - val_loss: 0.0043 - val_accuracy: 0.9973\n",
            "Epoch 27/50\n",
            "68/69 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9881\n",
            "Epoch 00027: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9881 - val_loss: 0.0036 - val_accuracy: 0.9973\n",
            "Epoch 28/50\n",
            "69/69 [==============================] - ETA: 0s - loss: 0.0572 - accuracy: 0.9862\n",
            "Epoch 00028: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0572 - accuracy: 0.9862 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 29/50\n",
            "68/69 [============================>.] - ETA: 0s - loss: 0.0365 - accuracy: 0.9908\n",
            "Epoch 00029: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0364 - accuracy: 0.9908 - val_loss: 0.0033 - val_accuracy: 0.9973\n",
            "Epoch 30/50\n",
            "46/69 [===================>..........] - ETA: 0s - loss: 0.0352 - accuracy: 0.9891\n",
            "Epoch 00030: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0387 - accuracy: 0.9908 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 31/50\n",
            "61/69 [=========================>....] - ETA: 0s - loss: 0.0326 - accuracy: 0.9887\n",
            "Epoch 00031: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0362 - accuracy: 0.9881 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 32/50\n",
            "65/69 [===========================>..] - ETA: 0s - loss: 0.0501 - accuracy: 0.9894\n",
            "Epoch 00032: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0480 - accuracy: 0.9899 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 33/50\n",
            "63/69 [==========================>...] - ETA: 0s - loss: 0.0144 - accuracy: 0.9950\n",
            "Epoch 00033: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0134 - accuracy: 0.9954 - val_loss: 8.6222e-04 - val_accuracy: 1.0000\n",
            "Epoch 34/50\n",
            "65/69 [===========================>..] - ETA: 0s - loss: 0.0257 - accuracy: 0.9913\n",
            "Epoch 00034: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0248 - accuracy: 0.9917 - val_loss: 8.0047e-04 - val_accuracy: 1.0000\n",
            "Epoch 35/50\n",
            "65/69 [===========================>..] - ETA: 0s - loss: 0.0189 - accuracy: 0.9933\n",
            "Epoch 00035: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9936 - val_loss: 0.0024 - val_accuracy: 0.9973\n",
            "Epoch 36/50\n",
            "62/69 [=========================>....] - ETA: 0s - loss: 0.0278 - accuracy: 0.9940\n",
            "Epoch 00036: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0259 - accuracy: 0.9945 - val_loss: 0.0034 - val_accuracy: 0.9973\n",
            "Epoch 37/50\n",
            "61/69 [=========================>....] - ETA: 0s - loss: 0.0277 - accuracy: 0.9918\n",
            "Epoch 00037: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9908 - val_loss: 0.0055 - val_accuracy: 0.9973\n",
            "Epoch 38/50\n",
            "62/69 [=========================>....] - ETA: 0s - loss: 0.0204 - accuracy: 0.9950\n",
            "Epoch 00038: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0191 - accuracy: 0.9954 - val_loss: 0.0029 - val_accuracy: 0.9973\n",
            "Epoch 39/50\n",
            "62/69 [=========================>....] - ETA: 0s - loss: 0.0281 - accuracy: 0.9919\n",
            "Epoch 00039: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.0258 - accuracy: 0.9927 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 40/50\n",
            "68/69 [============================>.] - ETA: 0s - loss: 0.0263 - accuracy: 0.9917\n",
            "Epoch 00040: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0263 - accuracy: 0.9917 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 41/50\n",
            "57/69 [=======================>......] - ETA: 0s - loss: 0.0173 - accuracy: 0.9956\n",
            "Epoch 00041: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0165 - accuracy: 0.9954 - val_loss: 9.1278e-04 - val_accuracy: 1.0000\n",
            "Epoch 42/50\n",
            "64/69 [==========================>...] - ETA: 0s - loss: 0.0178 - accuracy: 0.9941\n",
            "Epoch 00042: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9945 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 43/50\n",
            "63/69 [==========================>...] - ETA: 0s - loss: 0.0076 - accuracy: 0.9970\n",
            "Epoch 00043: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0072 - accuracy: 0.9972 - val_loss: 8.1763e-04 - val_accuracy: 1.0000\n",
            "Epoch 44/50\n",
            "66/69 [===========================>..] - ETA: 0s - loss: 0.0204 - accuracy: 0.9943\n",
            "Epoch 00044: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9936 - val_loss: 9.7916e-04 - val_accuracy: 1.0000\n",
            "Epoch 45/50\n",
            "59/69 [========================>.....] - ETA: 0s - loss: 0.0245 - accuracy: 0.9936\n",
            "Epoch 00045: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0280 - accuracy: 0.9927 - val_loss: 4.4060e-04 - val_accuracy: 1.0000\n",
            "Epoch 46/50\n",
            "66/69 [===========================>..] - ETA: 0s - loss: 0.0122 - accuracy: 0.9962\n",
            "Epoch 00046: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0122 - accuracy: 0.9963 - val_loss: 1.5613e-04 - val_accuracy: 1.0000\n",
            "Epoch 47/50\n",
            "49/69 [====================>.........] - ETA: 0s - loss: 0.0258 - accuracy: 0.9949\n",
            "Epoch 00047: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 6ms/step - loss: 0.0191 - accuracy: 0.9963 - val_loss: 1.5997e-04 - val_accuracy: 1.0000\n",
            "Epoch 48/50\n",
            "47/69 [===================>..........] - ETA: 0s - loss: 0.0096 - accuracy: 0.9960\n",
            "Epoch 00048: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0210 - accuracy: 0.9945 - val_loss: 5.9769e-04 - val_accuracy: 1.0000\n",
            "Epoch 49/50\n",
            "68/69 [============================>.] - ETA: 0s - loss: 0.0227 - accuracy: 0.9963\n",
            "Epoch 00049: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 5ms/step - loss: 0.0227 - accuracy: 0.9963 - val_loss: 7.9561e-04 - val_accuracy: 1.0000\n",
            "Epoch 50/50\n",
            "52/69 [=====================>........] - ETA: 0s - loss: 0.0077 - accuracy: 0.9976\n",
            "Epoch 00050: saving model to /content/drive/MyDrive/EE603-Project/model_saved\n",
            "69/69 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9963 - val_loss: 4.9321e-04 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fdc08d6f410>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjpW0l3xIva9",
        "outputId": "7119a9a4-5424-4c09-c671-a097ff110534"
      },
      "source": [
        "os.listdir(checkpoint_dir)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Pritam_music.wav',\n",
              " 'Speech.wav',\n",
              " 'TrainLabels.csv',\n",
              " 'files',\n",
              " 'model_saved',\n",
              " 'val_set',\n",
              " 'model_saved.index',\n",
              " 'model_saved.data-00000-of-00001',\n",
              " 'checkpoint']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgBfbU1B0-pn"
      },
      "source": [
        "# Performing Prediction on Validation Data Provided "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kuRZ3rAXLnjr"
      },
      "source": [
        "Model2 = model()"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xs3r80ylNFow",
        "outputId": "34d6079c-d4ee-42e2-dac4-bf503bdc93c4"
      },
      "source": [
        "Model2.load_weights(checkpoint_path)"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fdbff366f50>"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akJ-Dn81yrjq"
      },
      "source": [
        "test_Data_path = '/content/drive/MyDrive/EE603-Project/val_set/wav'\n",
        "\n",
        "sheet_name = \"test_lables\"\n",
        "url = f\"https://docs.google.com/spreadsheets/d/1_s_xHMGRWnH7F9faavlENbVX45eqGAnzeUec4P1vjvQ/gviz/tq?tqx=out:csv&sheet={sheet_name}\"\n",
        "\n",
        "df_test = pd.read_csv(url)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1szwx3GlXn3C"
      },
      "source": [
        "window_length = 2500\n",
        "window_length_time = window_length/Fs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "vYZgtgcr8j9m",
        "outputId": "521fef87-df66-45e3-b205-b4a8742cc00d"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>onset</th>\n",
              "      <th>offset</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S001</td>\n",
              "      <td>0.7545</td>\n",
              "      <td>1.963</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S001</td>\n",
              "      <td>3.0330</td>\n",
              "      <td>4.365</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S001</td>\n",
              "      <td>5.2850</td>\n",
              "      <td>6.591</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S001</td>\n",
              "      <td>7.6340</td>\n",
              "      <td>9.019</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S002</td>\n",
              "      <td>0.1580</td>\n",
              "      <td>1.060</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  filename   onset  offset   class\n",
              "0     S001  0.7545   1.963  speech\n",
              "1     S001  3.0330   4.365  speech\n",
              "2     S001  5.2850   6.591  speech\n",
              "3     S001  7.6340   9.019  speech\n",
              "4     S002  0.1580   1.060  speech"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kjVXXwnlFMEA"
      },
      "source": [
        "def extract_mfcc_test(audio):\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=Fs, n_mfcc=n_mfcc)\n",
        "    return np.mean(mfccs.T,axis=0)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uI8SWhF0_CWt"
      },
      "source": [
        "def func(df_test,window_length = 2500):\n",
        "\n",
        "  features=[]\n",
        "  final =[]\n",
        "  window_length = 2500\n",
        "\n",
        "  for id,ro in tqdm(df_test.iterrows()):\n",
        "\n",
        "      f = os.path.join(os.path.abspath(test_Data_path),str(ro[\"filename\"]+'.wav'))\n",
        "      if ro[\"filename\"] in final:\n",
        "        continue;\n",
        "      \n",
        "      final.append(ro[\"filename\"])\n",
        "      audio,_ = librosa.load(f, Fs)\n",
        "\n",
        "      for i in range(int(audio.shape[0]/window_length)):\n",
        "        tempa = audio[i*window_length:(i+1)*window_length]\n",
        "        td=extract_mfcc_test(tempa)\n",
        "        fname = str(ro[\"filename\"]) + str(i)\n",
        "        features.append([fname, td])\n",
        "\n",
        "  features_df=pd.DataFrame(features,columns=['filename','mfccs'])    \n",
        "  return final, features_df\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ufMUxQCpSiar",
        "outputId": "3b1a7f0d-4f83-453d-ea79-0bb93ea01275"
      },
      "source": [
        "final, features_df = func(df_test,window_length = 2500)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "40it [00:17,  2.27it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VAXC_dF6UgiO",
        "outputId": "b504c326-4ae4-48ad-e1fa-cf6d728368fd"
      },
      "source": [
        "features_df.head()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>mfccs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S0010</td>\n",
              "      <td>[-499.80484, 97.405014, -6.242565, 29.702097, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S0011</td>\n",
              "      <td>[-501.80035, 103.22322, -4.691728, 31.590801, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S0012</td>\n",
              "      <td>[-511.67734, 102.85643, 3.918148, 26.303196, 8...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S0013</td>\n",
              "      <td>[-521.1769, 105.81555, 6.26138, 27.474567, 8.4...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S0014</td>\n",
              "      <td>[-463.32495, 110.38657, 16.875725, 25.956945, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  filename                                              mfccs\n",
              "0    S0010  [-499.80484, 97.405014, -6.242565, 29.702097, ...\n",
              "1    S0011  [-501.80035, 103.22322, -4.691728, 31.590801, ...\n",
              "2    S0012  [-511.67734, 102.85643, 3.918148, 26.303196, 8...\n",
              "3    S0013  [-521.1769, 105.81555, 6.26138, 27.474567, 8.4...\n",
              "4    S0014  [-463.32495, 110.38657, 16.875725, 25.956945, ..."
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8SaCOjFTk6_"
      },
      "source": [
        "def preprocessing(features_df,final,Model2):\n",
        "\n",
        "  X_test = np.array(features_df['mfccs'].tolist())\n",
        "  result= []\n",
        "\n",
        "  for i in tqdm(range(len(X_test))):\n",
        "    a = Model2.predict(X_test[i].reshape(1,-1))\n",
        "    result.append(a[0])\n",
        "  \n",
        "  res = np.array(result)\n",
        "  result_dict = {}\n",
        "\n",
        "  for i in range(res.shape[0]):\n",
        "    arr = res[i]\n",
        "    index = np.where(arr == np.amax(arr))[0][0]\n",
        "\n",
        "    if index == 0:\n",
        "      result_dict[i] = \"music\"\n",
        "    elif index == 1:\n",
        "      result_dict[i] = \"silence\"\n",
        "    else:\n",
        "      result_dict[i] = \"speech\"\n",
        "  \n",
        "  window_length_time = window_length/Fs\n",
        "  tempar = ['music','speech']\n",
        "  arr = []\n",
        "\n",
        "  for id in result_dict:\n",
        "    if result_dict[id] in tempar:\n",
        "      arr.append(id)\n",
        "  \n",
        "  for item in arr:\n",
        "    if (item + 3) < len(result_dict):\n",
        "      if result_dict[item] == result_dict[item+2]:\n",
        "        result_dict[item+1] = result_dict[item]\n",
        "  return result_dict"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5707ZJXDYunD",
        "outputId": "821d7232-ff5c-40ac-960a-e178d174af07"
      },
      "source": [
        "result_dict = preprocessing(features_df,final,Model2)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 762/762 [00:37<00:00, 20.28it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZWbtj3uZIpk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3f74451-9f6f-45c1-a530-6b0a4199084d"
      },
      "source": [
        "result_dict"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'silence',\n",
              " 1: 'silence',\n",
              " 2: 'silence',\n",
              " 3: 'silence',\n",
              " 4: 'silence',\n",
              " 5: 'music',\n",
              " 6: 'music',\n",
              " 7: 'music',\n",
              " 8: 'music',\n",
              " 9: 'music',\n",
              " 10: 'silence',\n",
              " 11: 'silence',\n",
              " 12: 'silence',\n",
              " 13: 'silence',\n",
              " 14: 'silence',\n",
              " 15: 'silence',\n",
              " 16: 'silence',\n",
              " 17: 'silence',\n",
              " 18: 'silence',\n",
              " 19: 'silence',\n",
              " 20: 'music',\n",
              " 21: 'music',\n",
              " 22: 'music',\n",
              " 23: 'music',\n",
              " 24: 'music',\n",
              " 25: 'music',\n",
              " 26: 'silence',\n",
              " 27: 'silence',\n",
              " 28: 'silence',\n",
              " 29: 'silence',\n",
              " 30: 'silence',\n",
              " 31: 'silence',\n",
              " 32: 'silence',\n",
              " 33: 'silence',\n",
              " 34: 'silence',\n",
              " 35: 'music',\n",
              " 36: 'music',\n",
              " 37: 'silence',\n",
              " 38: 'speech',\n",
              " 39: 'music',\n",
              " 40: 'music',\n",
              " 41: 'silence',\n",
              " 42: 'silence',\n",
              " 43: 'silence',\n",
              " 44: 'silence',\n",
              " 45: 'silence',\n",
              " 46: 'silence',\n",
              " 47: 'silence',\n",
              " 48: 'silence',\n",
              " 49: 'music',\n",
              " 50: 'speech',\n",
              " 51: 'silence',\n",
              " 52: 'music',\n",
              " 53: 'music',\n",
              " 54: 'music',\n",
              " 55: 'music',\n",
              " 56: 'silence',\n",
              " 57: 'silence',\n",
              " 58: 'silence',\n",
              " 59: 'silence',\n",
              " 60: 'silence',\n",
              " 61: 'silence',\n",
              " 62: 'silence',\n",
              " 63: 'silence',\n",
              " 64: 'silence',\n",
              " 65: 'speech',\n",
              " 66: 'silence',\n",
              " 67: 'music',\n",
              " 68: 'music',\n",
              " 69: 'silence',\n",
              " 70: 'silence',\n",
              " 71: 'silence',\n",
              " 72: 'silence',\n",
              " 73: 'silence',\n",
              " 74: 'silence',\n",
              " 75: 'silence',\n",
              " 76: 'silence',\n",
              " 77: 'silence',\n",
              " 78: 'silence',\n",
              " 79: 'silence',\n",
              " 80: 'silence',\n",
              " 81: 'speech',\n",
              " 82: 'speech',\n",
              " 83: 'speech',\n",
              " 84: 'speech',\n",
              " 85: 'speech',\n",
              " 86: 'speech',\n",
              " 87: 'speech',\n",
              " 88: 'speech',\n",
              " 89: 'silence',\n",
              " 90: 'silence',\n",
              " 91: 'silence',\n",
              " 92: 'silence',\n",
              " 93: 'silence',\n",
              " 94: 'silence',\n",
              " 95: 'silence',\n",
              " 96: 'silence',\n",
              " 97: 'silence',\n",
              " 98: 'silence',\n",
              " 99: 'music',\n",
              " 100: 'silence',\n",
              " 101: 'speech',\n",
              " 102: 'speech',\n",
              " 103: 'music',\n",
              " 104: 'silence',\n",
              " 105: 'silence',\n",
              " 106: 'silence',\n",
              " 107: 'silence',\n",
              " 108: 'silence',\n",
              " 109: 'silence',\n",
              " 110: 'silence',\n",
              " 111: 'silence',\n",
              " 112: 'silence',\n",
              " 113: 'silence',\n",
              " 114: 'music',\n",
              " 115: 'music',\n",
              " 116: 'music',\n",
              " 117: 'music',\n",
              " 118: 'music',\n",
              " 119: 'music',\n",
              " 120: 'music',\n",
              " 121: 'music',\n",
              " 122: 'music',\n",
              " 123: 'music',\n",
              " 124: 'music',\n",
              " 125: 'silence',\n",
              " 126: 'silence',\n",
              " 127: 'silence',\n",
              " 128: 'silence',\n",
              " 129: 'silence',\n",
              " 130: 'silence',\n",
              " 131: 'silence',\n",
              " 132: 'silence',\n",
              " 133: 'silence',\n",
              " 134: 'speech',\n",
              " 135: 'speech',\n",
              " 136: 'music',\n",
              " 137: 'silence',\n",
              " 138: 'silence',\n",
              " 139: 'silence',\n",
              " 140: 'silence',\n",
              " 141: 'silence',\n",
              " 142: 'silence',\n",
              " 143: 'silence',\n",
              " 144: 'silence',\n",
              " 145: 'silence',\n",
              " 146: 'silence',\n",
              " 147: 'silence',\n",
              " 148: 'speech',\n",
              " 149: 'silence',\n",
              " 150: 'music',\n",
              " 151: 'music',\n",
              " 152: 'music',\n",
              " 153: 'music',\n",
              " 154: 'music',\n",
              " 155: 'silence',\n",
              " 156: 'silence',\n",
              " 157: 'silence',\n",
              " 158: 'silence',\n",
              " 159: 'silence',\n",
              " 160: 'silence',\n",
              " 161: 'music',\n",
              " 162: 'music',\n",
              " 163: 'silence',\n",
              " 164: 'silence',\n",
              " 165: 'music',\n",
              " 166: 'music',\n",
              " 167: 'music',\n",
              " 168: 'music',\n",
              " 169: 'speech',\n",
              " 170: 'silence',\n",
              " 171: 'silence',\n",
              " 172: 'silence',\n",
              " 173: 'music',\n",
              " 174: 'music',\n",
              " 175: 'music',\n",
              " 176: 'music',\n",
              " 177: 'music',\n",
              " 178: 'silence',\n",
              " 179: 'silence',\n",
              " 180: 'music',\n",
              " 181: 'silence',\n",
              " 182: 'silence',\n",
              " 183: 'silence',\n",
              " 184: 'silence',\n",
              " 185: 'silence',\n",
              " 186: 'silence',\n",
              " 187: 'silence',\n",
              " 188: 'silence',\n",
              " 189: 'silence',\n",
              " 190: 'silence',\n",
              " 191: 'silence',\n",
              " 192: 'silence',\n",
              " 193: 'silence',\n",
              " 194: 'silence',\n",
              " 195: 'music',\n",
              " 196: 'speech',\n",
              " 197: 'speech',\n",
              " 198: 'speech',\n",
              " 199: 'silence',\n",
              " 200: 'silence',\n",
              " 201: 'music',\n",
              " 202: 'music',\n",
              " 203: 'music',\n",
              " 204: 'music',\n",
              " 205: 'music',\n",
              " 206: 'music',\n",
              " 207: 'silence',\n",
              " 208: 'silence',\n",
              " 209: 'silence',\n",
              " 210: 'silence',\n",
              " 211: 'silence',\n",
              " 212: 'silence',\n",
              " 213: 'silence',\n",
              " 214: 'silence',\n",
              " 215: 'silence',\n",
              " 216: 'silence',\n",
              " 217: 'music',\n",
              " 218: 'music',\n",
              " 219: 'music',\n",
              " 220: 'music',\n",
              " 221: 'music',\n",
              " 222: 'speech',\n",
              " 223: 'silence',\n",
              " 224: 'music',\n",
              " 225: 'music',\n",
              " 226: 'music',\n",
              " 227: 'music',\n",
              " 228: 'music',\n",
              " 229: 'silence',\n",
              " 230: 'silence',\n",
              " 231: 'silence',\n",
              " 232: 'silence',\n",
              " 233: 'silence',\n",
              " 234: 'silence',\n",
              " 235: 'silence',\n",
              " 236: 'silence',\n",
              " 237: 'silence',\n",
              " 238: 'silence',\n",
              " 239: 'speech',\n",
              " 240: 'speech',\n",
              " 241: 'music',\n",
              " 242: 'music',\n",
              " 243: 'music',\n",
              " 244: 'music',\n",
              " 245: 'music',\n",
              " 246: 'speech',\n",
              " 247: 'silence',\n",
              " 248: 'silence',\n",
              " 249: 'silence',\n",
              " 250: 'silence',\n",
              " 251: 'silence',\n",
              " 252: 'silence',\n",
              " 253: 'silence',\n",
              " 254: 'silence',\n",
              " 255: 'silence',\n",
              " 256: 'silence',\n",
              " 257: 'music',\n",
              " 258: 'music',\n",
              " 259: 'speech',\n",
              " 260: 'speech',\n",
              " 261: 'speech',\n",
              " 262: 'speech',\n",
              " 263: 'speech',\n",
              " 264: 'speech',\n",
              " 265: 'music',\n",
              " 266: 'music',\n",
              " 267: 'silence',\n",
              " 268: 'silence',\n",
              " 269: 'silence',\n",
              " 270: 'silence',\n",
              " 271: 'silence',\n",
              " 272: 'silence',\n",
              " 273: 'silence',\n",
              " 274: 'silence',\n",
              " 275: 'silence',\n",
              " 276: 'music',\n",
              " 277: 'music',\n",
              " 278: 'music',\n",
              " 279: 'music',\n",
              " 280: 'music',\n",
              " 281: 'music',\n",
              " 282: 'music',\n",
              " 283: 'music',\n",
              " 284: 'music',\n",
              " 285: 'silence',\n",
              " 286: 'silence',\n",
              " 287: 'silence',\n",
              " 288: 'silence',\n",
              " 289: 'silence',\n",
              " 290: 'silence',\n",
              " 291: 'silence',\n",
              " 292: 'silence',\n",
              " 293: 'silence',\n",
              " 294: 'silence',\n",
              " 295: 'silence',\n",
              " 296: 'silence',\n",
              " 297: 'silence',\n",
              " 298: 'music',\n",
              " 299: 'music',\n",
              " 300: 'music',\n",
              " 301: 'music',\n",
              " 302: 'music',\n",
              " 303: 'music',\n",
              " 304: 'silence',\n",
              " 305: 'silence',\n",
              " 306: 'silence',\n",
              " 307: 'silence',\n",
              " 308: 'silence',\n",
              " 309: 'silence',\n",
              " 310: 'silence',\n",
              " 311: 'silence',\n",
              " 312: 'silence',\n",
              " 313: 'silence',\n",
              " 314: 'silence',\n",
              " 315: 'silence',\n",
              " 316: 'silence',\n",
              " 317: 'silence',\n",
              " 318: 'silence',\n",
              " 319: 'silence',\n",
              " 320: 'silence',\n",
              " 321: 'silence',\n",
              " 322: 'speech',\n",
              " 323: 'speech',\n",
              " 324: 'speech',\n",
              " 325: 'speech',\n",
              " 326: 'speech',\n",
              " 327: 'speech',\n",
              " 328: 'speech',\n",
              " 329: 'silence',\n",
              " 330: 'silence',\n",
              " 331: 'silence',\n",
              " 332: 'silence',\n",
              " 333: 'silence',\n",
              " 334: 'silence',\n",
              " 335: 'silence',\n",
              " 336: 'silence',\n",
              " 337: 'music',\n",
              " 338: 'music',\n",
              " 339: 'music',\n",
              " 340: 'music',\n",
              " 341: 'music',\n",
              " 342: 'music',\n",
              " 343: 'music',\n",
              " 344: 'silence',\n",
              " 345: 'silence',\n",
              " 346: 'silence',\n",
              " 347: 'silence',\n",
              " 348: 'silence',\n",
              " 349: 'silence',\n",
              " 350: 'silence',\n",
              " 351: 'silence',\n",
              " 352: 'silence',\n",
              " 353: 'silence',\n",
              " 354: 'silence',\n",
              " 355: 'silence',\n",
              " 356: 'music',\n",
              " 357: 'silence',\n",
              " 358: 'silence',\n",
              " 359: 'silence',\n",
              " 360: 'silence',\n",
              " 361: 'silence',\n",
              " 362: 'silence',\n",
              " 363: 'silence',\n",
              " 364: 'silence',\n",
              " 365: 'silence',\n",
              " 366: 'silence',\n",
              " 367: 'silence',\n",
              " 368: 'silence',\n",
              " 369: 'silence',\n",
              " 370: 'silence',\n",
              " 371: 'silence',\n",
              " 372: 'silence',\n",
              " 373: 'silence',\n",
              " 374: 'silence',\n",
              " 375: 'silence',\n",
              " 376: 'silence',\n",
              " 377: 'silence',\n",
              " 378: 'silence',\n",
              " 379: 'silence',\n",
              " 380: 'silence',\n",
              " 381: 'music',\n",
              " 382: 'music',\n",
              " 383: 'music',\n",
              " 384: 'music',\n",
              " 385: 'music',\n",
              " 386: 'music',\n",
              " 387: 'music',\n",
              " 388: 'music',\n",
              " 389: 'music',\n",
              " 390: 'music',\n",
              " 391: 'music',\n",
              " 392: 'music',\n",
              " 393: 'music',\n",
              " 394: 'music',\n",
              " 395: 'music',\n",
              " 396: 'music',\n",
              " 397: 'music',\n",
              " 398: 'music',\n",
              " 399: 'silence',\n",
              " 400: 'silence',\n",
              " 401: 'silence',\n",
              " 402: 'music',\n",
              " 403: 'music',\n",
              " 404: 'music',\n",
              " 405: 'music',\n",
              " 406: 'music',\n",
              " 407: 'music',\n",
              " 408: 'music',\n",
              " 409: 'music',\n",
              " 410: 'music',\n",
              " 411: 'music',\n",
              " 412: 'music',\n",
              " 413: 'music',\n",
              " 414: 'music',\n",
              " 415: 'music',\n",
              " 416: 'music',\n",
              " 417: 'music',\n",
              " 418: 'music',\n",
              " 419: 'music',\n",
              " 420: 'music',\n",
              " 421: 'music',\n",
              " 422: 'music',\n",
              " 423: 'music',\n",
              " 424: 'music',\n",
              " 425: 'music',\n",
              " 426: 'music',\n",
              " 427: 'music',\n",
              " 428: 'music',\n",
              " 429: 'music',\n",
              " 430: 'music',\n",
              " 431: 'music',\n",
              " 432: 'music',\n",
              " 433: 'music',\n",
              " 434: 'music',\n",
              " 435: 'silence',\n",
              " 436: 'silence',\n",
              " 437: 'silence',\n",
              " 438: 'silence',\n",
              " 439: 'silence',\n",
              " 440: 'silence',\n",
              " 441: 'silence',\n",
              " 442: 'silence',\n",
              " 443: 'silence',\n",
              " 444: 'silence',\n",
              " 445: 'music',\n",
              " 446: 'music',\n",
              " 447: 'music',\n",
              " 448: 'music',\n",
              " 449: 'music',\n",
              " 450: 'music',\n",
              " 451: 'music',\n",
              " 452: 'music',\n",
              " 453: 'music',\n",
              " 454: 'music',\n",
              " 455: 'music',\n",
              " 456: 'music',\n",
              " 457: 'silence',\n",
              " 458: 'silence',\n",
              " 459: 'silence',\n",
              " 460: 'silence',\n",
              " 461: 'silence',\n",
              " 462: 'music',\n",
              " 463: 'music',\n",
              " 464: 'music',\n",
              " 465: 'music',\n",
              " 466: 'music',\n",
              " 467: 'music',\n",
              " 468: 'silence',\n",
              " 469: 'silence',\n",
              " 470: 'silence',\n",
              " 471: 'music',\n",
              " 472: 'music',\n",
              " 473: 'music',\n",
              " 474: 'music',\n",
              " 475: 'music',\n",
              " 476: 'music',\n",
              " 477: 'music',\n",
              " 478: 'music',\n",
              " 479: 'music',\n",
              " 480: 'music',\n",
              " 481: 'silence',\n",
              " 482: 'silence',\n",
              " 483: 'music',\n",
              " 484: 'music',\n",
              " 485: 'music',\n",
              " 486: 'music',\n",
              " 487: 'music',\n",
              " 488: 'music',\n",
              " 489: 'speech',\n",
              " 490: 'speech',\n",
              " 491: 'music',\n",
              " 492: 'music',\n",
              " 493: 'music',\n",
              " 494: 'music',\n",
              " 495: 'silence',\n",
              " 496: 'silence',\n",
              " 497: 'silence',\n",
              " 498: 'silence',\n",
              " 499: 'silence',\n",
              " 500: 'silence',\n",
              " 501: 'silence',\n",
              " 502: 'silence',\n",
              " 503: 'silence',\n",
              " 504: 'silence',\n",
              " 505: 'silence',\n",
              " 506: 'silence',\n",
              " 507: 'silence',\n",
              " 508: 'silence',\n",
              " 509: 'speech',\n",
              " 510: 'silence',\n",
              " 511: 'silence',\n",
              " 512: 'speech',\n",
              " 513: 'speech',\n",
              " 514: 'speech',\n",
              " 515: 'speech',\n",
              " 516: 'speech',\n",
              " 517: 'speech',\n",
              " 518: 'speech',\n",
              " 519: 'speech',\n",
              " 520: 'silence',\n",
              " 521: 'silence',\n",
              " 522: 'silence',\n",
              " 523: 'silence',\n",
              " 524: 'silence',\n",
              " 525: 'silence',\n",
              " 526: 'music',\n",
              " 527: 'music',\n",
              " 528: 'music',\n",
              " 529: 'music',\n",
              " 530: 'music',\n",
              " 531: 'music',\n",
              " 532: 'music',\n",
              " 533: 'silence',\n",
              " 534: 'silence',\n",
              " 535: 'silence',\n",
              " 536: 'silence',\n",
              " 537: 'silence',\n",
              " 538: 'silence',\n",
              " 539: 'silence',\n",
              " 540: 'silence',\n",
              " 541: 'silence',\n",
              " 542: 'silence',\n",
              " 543: 'silence',\n",
              " 544: 'silence',\n",
              " 545: 'silence',\n",
              " 546: 'silence',\n",
              " 547: 'speech',\n",
              " 548: 'speech',\n",
              " 549: 'speech',\n",
              " 550: 'speech',\n",
              " 551: 'speech',\n",
              " 552: 'speech',\n",
              " 553: 'music',\n",
              " 554: 'silence',\n",
              " 555: 'silence',\n",
              " 556: 'silence',\n",
              " 557: 'silence',\n",
              " 558: 'speech',\n",
              " 559: 'speech',\n",
              " 560: 'speech',\n",
              " 561: 'silence',\n",
              " 562: 'silence',\n",
              " 563: 'silence',\n",
              " 564: 'silence',\n",
              " 565: 'silence',\n",
              " 566: 'silence',\n",
              " 567: 'silence',\n",
              " 568: 'silence',\n",
              " 569: 'silence',\n",
              " 570: 'silence',\n",
              " 571: 'silence',\n",
              " 572: 'silence',\n",
              " 573: 'music',\n",
              " 574: 'music',\n",
              " 575: 'music',\n",
              " 576: 'music',\n",
              " 577: 'music',\n",
              " 578: 'music',\n",
              " 579: 'music',\n",
              " 580: 'music',\n",
              " 581: 'silence',\n",
              " 582: 'silence',\n",
              " 583: 'silence',\n",
              " 584: 'silence',\n",
              " 585: 'silence',\n",
              " 586: 'silence',\n",
              " 587: 'silence',\n",
              " 588: 'silence',\n",
              " 589: 'speech',\n",
              " 590: 'speech',\n",
              " 591: 'silence',\n",
              " 592: 'silence',\n",
              " 593: 'speech',\n",
              " 594: 'silence',\n",
              " 595: 'music',\n",
              " 596: 'speech',\n",
              " 597: 'speech',\n",
              " 598: 'speech',\n",
              " 599: 'speech',\n",
              " 600: 'silence',\n",
              " 601: 'silence',\n",
              " 602: 'silence',\n",
              " 603: 'silence',\n",
              " 604: 'silence',\n",
              " 605: 'silence',\n",
              " 606: 'music',\n",
              " 607: 'speech',\n",
              " 608: 'speech',\n",
              " 609: 'music',\n",
              " 610: 'silence',\n",
              " 611: 'silence',\n",
              " 612: 'silence',\n",
              " 613: 'speech',\n",
              " 614: 'speech',\n",
              " 615: 'silence',\n",
              " 616: 'silence',\n",
              " 617: 'silence',\n",
              " 618: 'silence',\n",
              " 619: 'silence',\n",
              " 620: 'silence',\n",
              " 621: 'silence',\n",
              " 622: 'silence',\n",
              " 623: 'silence',\n",
              " 624: 'silence',\n",
              " 625: 'music',\n",
              " 626: 'music',\n",
              " 627: 'music',\n",
              " 628: 'music',\n",
              " 629: 'music',\n",
              " 630: 'music',\n",
              " 631: 'music',\n",
              " 632: 'music',\n",
              " 633: 'silence',\n",
              " 634: 'silence',\n",
              " 635: 'silence',\n",
              " 636: 'silence',\n",
              " 637: 'music',\n",
              " 638: 'music',\n",
              " 639: 'music',\n",
              " 640: 'music',\n",
              " 641: 'music',\n",
              " 642: 'music',\n",
              " 643: 'music',\n",
              " 644: 'music',\n",
              " 645: 'silence',\n",
              " 646: 'silence',\n",
              " 647: 'silence',\n",
              " 648: 'silence',\n",
              " 649: 'silence',\n",
              " 650: 'silence',\n",
              " 651: 'silence',\n",
              " 652: 'silence',\n",
              " 653: 'music',\n",
              " 654: 'speech',\n",
              " 655: 'speech',\n",
              " 656: 'speech',\n",
              " 657: 'speech',\n",
              " 658: 'speech',\n",
              " 659: 'speech',\n",
              " 660: 'speech',\n",
              " 661: 'speech',\n",
              " 662: 'speech',\n",
              " 663: 'silence',\n",
              " 664: 'silence',\n",
              " 665: 'silence',\n",
              " 666: 'silence',\n",
              " 667: 'silence',\n",
              " 668: 'silence',\n",
              " 669: 'silence',\n",
              " 670: 'speech',\n",
              " 671: 'speech',\n",
              " 672: 'speech',\n",
              " 673: 'speech',\n",
              " 674: 'speech',\n",
              " 675: 'speech',\n",
              " 676: 'speech',\n",
              " 677: 'silence',\n",
              " 678: 'silence',\n",
              " 679: 'silence',\n",
              " 680: 'silence',\n",
              " 681: 'silence',\n",
              " 682: 'speech',\n",
              " 683: 'speech',\n",
              " 684: 'silence',\n",
              " 685: 'silence',\n",
              " 686: 'silence',\n",
              " 687: 'silence',\n",
              " 688: 'silence',\n",
              " 689: 'silence',\n",
              " 690: 'silence',\n",
              " 691: 'silence',\n",
              " 692: 'silence',\n",
              " 693: 'silence',\n",
              " 694: 'silence',\n",
              " 695: 'silence',\n",
              " 696: 'silence',\n",
              " 697: 'silence',\n",
              " 698: 'silence',\n",
              " 699: 'silence',\n",
              " 700: 'silence',\n",
              " 701: 'speech',\n",
              " 702: 'silence',\n",
              " 703: 'silence',\n",
              " 704: 'speech',\n",
              " 705: 'speech',\n",
              " 706: 'speech',\n",
              " 707: 'speech',\n",
              " 708: 'speech',\n",
              " 709: 'speech',\n",
              " 710: 'speech',\n",
              " 711: 'speech',\n",
              " 712: 'silence',\n",
              " 713: 'silence',\n",
              " 714: 'silence',\n",
              " 715: 'silence',\n",
              " 716: 'silence',\n",
              " 717: 'silence',\n",
              " 718: 'music',\n",
              " 719: 'music',\n",
              " 720: 'music',\n",
              " 721: 'music',\n",
              " 722: 'music',\n",
              " 723: 'music',\n",
              " 724: 'music',\n",
              " 725: 'music',\n",
              " 726: 'music',\n",
              " 727: 'music',\n",
              " 728: 'music',\n",
              " 729: 'music',\n",
              " 730: 'silence',\n",
              " 731: 'silence',\n",
              " 732: 'silence',\n",
              " 733: 'silence',\n",
              " 734: 'silence',\n",
              " 735: 'silence',\n",
              " 736: 'silence',\n",
              " 737: 'speech',\n",
              " 738: 'speech',\n",
              " 739: 'speech',\n",
              " 740: 'speech',\n",
              " 741: 'speech',\n",
              " 742: 'music',\n",
              " 743: 'music',\n",
              " 744: 'music',\n",
              " 745: 'music',\n",
              " 746: 'music',\n",
              " 747: 'music',\n",
              " 748: 'music',\n",
              " 749: 'silence',\n",
              " 750: 'silence',\n",
              " 751: 'silence',\n",
              " 752: 'silence',\n",
              " 753: 'speech',\n",
              " 754: 'speech',\n",
              " 755: 'speech',\n",
              " 756: 'speech',\n",
              " 757: 'speech',\n",
              " 758: 'speech',\n",
              " 759: 'speech',\n",
              " 760: 'silence',\n",
              " 761: 'silence'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWDcrB8Xeco3"
      },
      "source": [
        "Some constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znsYvvT1efmT"
      },
      "source": [
        "file_length = 10 # since each file is of 10 second length\n",
        "n_frames = int(Fs*file_length/window_length)\n",
        "threshold = 6"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSmyi8q4ersL",
        "outputId": "217a97a7-865d-405f-81b1-797e1a659a88"
      },
      "source": [
        "n_frames"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "64"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvt8dj0wN40w"
      },
      "source": [
        "def predictf(result_dict):\n",
        "  count_dict = {'music':0,\n",
        "              'speech':0}\n",
        "\n",
        "  predictions = []\n",
        "  threshold = 10\n",
        "  cntMusic = 0\n",
        "  cntSpeech = 0\n",
        "\n",
        "  for id in result_dict:\n",
        "\n",
        "    if id == (len(result_dict) - 1):\n",
        "      if cntMusic >= threshold:\n",
        "        count_dict['music'] = 1\n",
        "      if cntSpeech >= threshold:\n",
        "        count_dict['speech'] = 1\n",
        "\n",
        "\n",
        "      predictions.append([count_dict['music'],count_dict['speech']])\n",
        "      break\n",
        "\n",
        "\n",
        "    \n",
        "    if id % n_frames == 0:\n",
        "      if id == 0:\n",
        "        continue\n",
        "      if cntMusic >= threshold:\n",
        "        count_dict['music'] = 1\n",
        "      if cntSpeech >= threshold:\n",
        "        count_dict['speech'] = 1\n",
        "\n",
        "\n",
        "      predictions.append([count_dict['music'],count_dict['speech']])\n",
        "\n",
        "      cntMusic = 0\n",
        "      cntSpeech = 0\n",
        "      \n",
        "      count_dict['music'] = 0\n",
        "      count_dict['speech'] = 0\n",
        "      continue\n",
        "    if result_dict[id] == 'music':\n",
        "      cntMusic +=1\n",
        "    elif result_dict[id] == 'speech':\n",
        "      cntSpeech += 1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  df = pd.DataFrame(predictions,columns=['music','speech'])\n",
        "  return df"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG5CEdtldUqD"
      },
      "source": [
        "df = predictf(result_dict)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 421
        },
        "id": "tRbQb7QvdZXo",
        "outputId": "05b4b26f-1147-427b-d4fa-ca0f2bcc03a9"
      },
      "source": [
        "df"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>music</th>\n",
              "      <th>speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    music  speech\n",
              "0       1       0\n",
              "1       1       1\n",
              "2       1       0\n",
              "3       1       0\n",
              "4       1       0\n",
              "5       1       0\n",
              "6       1       0\n",
              "7       1       0\n",
              "8       1       1\n",
              "9       1       1\n",
              "10      0       1\n",
              "11      1       1"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfUU_xIOooKx"
      },
      "source": [
        "# predicting for spectrograms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "VK7wCPKuQZZx",
        "outputId": "74ed740b-aa49-4457-d066-c18565db1a91"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>onset</th>\n",
              "      <th>offset</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S001</td>\n",
              "      <td>0.7545</td>\n",
              "      <td>1.963</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S001</td>\n",
              "      <td>3.0330</td>\n",
              "      <td>4.365</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S001</td>\n",
              "      <td>5.2850</td>\n",
              "      <td>6.591</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S001</td>\n",
              "      <td>7.6340</td>\n",
              "      <td>9.019</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S002</td>\n",
              "      <td>0.1580</td>\n",
              "      <td>1.060</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  filename   onset  offset   class\n",
              "0     S001  0.7545   1.963  speech\n",
              "1     S001  3.0330   4.365  speech\n",
              "2     S001  5.2850   6.591  speech\n",
              "3     S001  7.6340   9.019  speech\n",
              "4     S002  0.1580   1.060  speech"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoGVT3fNorjw"
      },
      "source": [
        "root = '/content/drive/MyDrive/EE603-Project/val_set/spectrogram'"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYQTeWBn2p6B"
      },
      "source": [
        "f = '/content/drive/MyDrive/EE603-Project/val_set/spectrogram/S007.npy'"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88cKBOKx3Bhr"
      },
      "source": [
        "S_db = np.load(f)\n",
        "S = librosa.db_to_power(S_db, ref=1.0)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LI-Awbv3yeQ",
        "outputId": "a4a6c237-6a06-4993-a64b-79603ef43391"
      },
      "source": [
        "S_db.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(513, 313)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j61ysyCaJFHK"
      },
      "source": [
        "Some Constants"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glZF3KQFJEF_"
      },
      "source": [
        "n_fft = 1024\n",
        "hop_length = 512\n",
        "win_length = 1024\n",
        "Fs = 16000"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iu0Ni4BZI0dG"
      },
      "source": [
        "def duration(S_db):\n",
        "  n_samples = (S_db.shape[1]-1)*hop_length + win_length\n",
        "  return int(np.floor(n_samples/Fs))"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ9IWf5jKZ5b"
      },
      "source": [
        "def samples_to_duration(n):\n",
        "  r = (n-1)*hop_length + win_length\n",
        "  return r/Fs"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xut7HYJcMnJ0",
        "outputId": "83e3106d-1788-4248-cbe5-bbfa5fc1df61"
      },
      "source": [
        "samples_to_duration(313)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10.048"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0soTbRytKyXh"
      },
      "source": [
        "def duration_to_samples(t):\n",
        "  n_s = t*Fs\n",
        "  return int(((n_s-win_length)/hop_length ) + 1)"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n766pd1pQNGG"
      },
      "source": [
        "window_length_time = samples_to_duration(1)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRWjo5evQUXV",
        "outputId": "13063d4c-ad44-4e63-e1a0-5ae8461eecf9"
      },
      "source": [
        "window_length_time"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.064"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C051pDnsL15J",
        "outputId": "f50cf54d-60e7-4f67-89fe-e9069b270d76"
      },
      "source": [
        "duration_to_samples(0.064)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "oVQ0N2l6ZaxI",
        "outputId": "94f18081-3061-43bf-b2b7-08d0a87a8fb1"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>onset</th>\n",
              "      <th>offset</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>S001</td>\n",
              "      <td>0.7545</td>\n",
              "      <td>1.963</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>S001</td>\n",
              "      <td>3.0330</td>\n",
              "      <td>4.365</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>S001</td>\n",
              "      <td>5.2850</td>\n",
              "      <td>6.591</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>S001</td>\n",
              "      <td>7.6340</td>\n",
              "      <td>9.019</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>S002</td>\n",
              "      <td>0.1580</td>\n",
              "      <td>1.060</td>\n",
              "      <td>speech</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  filename   onset  offset   class\n",
              "0     S001  0.7545   1.963  speech\n",
              "1     S001  3.0330   4.365  speech\n",
              "2     S001  5.2850   6.591  speech\n",
              "3     S001  7.6340   9.019  speech\n",
              "4     S002  0.1580   1.060  speech"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ml5PuKzTa_OM"
      },
      "source": [
        "# for id,ro in tqdm(df_test.iterrows()):\n",
        "\n",
        "#       print(os.path.join(os.path.abspath(root),str(ro[\"filename\"]+'.npy')))"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T_vskFxzdOhj",
        "outputId": "c003a6c2-1026-48c1-df4e-b2192dd3e724"
      },
      "source": [
        "dir_list"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['music_noisy4.npy',\n",
              " 'music_noisy7.npy',\n",
              " 'music_noisy10.npy',\n",
              " 'music+speech_noisy1.npy',\n",
              " 'music_noisy3.npy',\n",
              " 'music+speech_noisy10.npy',\n",
              " 'music_noisy2.npy',\n",
              " 'music+speech_noisy2.npy',\n",
              " 'music_noisy5.npy',\n",
              " 'music_noisy6.npy',\n",
              " 'music_noisy8.npy',\n",
              " 'music_noisy1.npy',\n",
              " 'music_noisy9.npy',\n",
              " 'S010.npy',\n",
              " 'S007.npy',\n",
              " 'S009.npy',\n",
              " 'music+speech_noisy4.npy',\n",
              " 'music+speech_noisy7.npy',\n",
              " 'S005.npy',\n",
              " 'music+speech_noisy9.npy',\n",
              " 'S002.npy',\n",
              " 'S006.npy',\n",
              " 'S008.npy',\n",
              " 'music+speech_noisy8.npy',\n",
              " 'music+speech_noisy3.npy',\n",
              " 'music+speech_noisy6.npy',\n",
              " 'S001.npy',\n",
              " 'S003.npy',\n",
              " 'music+speech_noisy5.npy',\n",
              " 'S004.npy']"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wc0N8OZfdVVD"
      },
      "source": [
        "def extract_mfcc_spects(root):\n",
        "  dir_list = os.listdir(root)\n",
        "  M = []\n",
        "  files = []\n",
        "  for file in dir_list:\n",
        "    \n",
        "    f = os.path.join(os.path.abspath(root),file)\n",
        "    S_db = np.load(f)\n",
        "    S = librosa.db_to_power(S_db, ref=1.0)\n",
        "    m = []\n",
        "    \n",
        "    for i in range(1,S.shape[1]):\n",
        "      segement = S[:,i]\n",
        "      m.append([librosa.feature.mfcc(y = None, S = segement,sr = Fs,n_mfcc = 20)])\n",
        "    \n",
        "    M.append([file,m])\n",
        "  return  pd.DataFrame(M,columns=['filename','mfccs'])"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkLvNwT6hXTl"
      },
      "source": [
        "# feat = extract_mfcc_spects(root)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "6VOD6Dxelc0G",
        "outputId": "36e5d7bd-ae3b-4366-d2ea-c9847f1db57b"
      },
      "source": [
        "# feat.head()"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>mfccs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>music_noisy4.npy</td>\n",
              "      <td>[[[2.5638371745099549424e-05, 3.06226195760160...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>music_noisy7.npy</td>\n",
              "      <td>[[[0.0056091838205212423337, 0.007713037813540...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>music_noisy10.npy</td>\n",
              "      <td>[[[2.0155175956358044068e-05, 7.05915245646461...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>music+speech_noisy1.npy</td>\n",
              "      <td>[[[3.4956031490022763402e-05, 3.19949882359048...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>music_noisy3.npy</td>\n",
              "      <td>[[[3.0551248141932833935e-05, 4.36611584564389...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  filename                                              mfccs\n",
              "0         music_noisy4.npy  [[[2.5638371745099549424e-05, 3.06226195760160...\n",
              "1         music_noisy7.npy  [[[0.0056091838205212423337, 0.007713037813540...\n",
              "2        music_noisy10.npy  [[[2.0155175956358044068e-05, 7.05915245646461...\n",
              "3  music+speech_noisy1.npy  [[[3.4956031490022763402e-05, 3.19949882359048...\n",
              "4         music_noisy3.npy  [[[3.0551248141932833935e-05, 4.36611584564389..."
            ]
          },
          "metadata": {},
          "execution_count": 189
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69CKAGoBl3Fd",
        "outputId": "a39832b1-5de5-4507-c189-f7affe7cbab4"
      },
      "source": [
        "len(feat)"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Kny6MiPmeCc"
      },
      "source": [
        "rand = np.array(feat['mfccs'].tolist())"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pEDABks9mxZ-",
        "outputId": "94349927-8391-4df6-e5d4-37cdfb186f14"
      },
      "source": [
        "rand.shape"
      ],
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(30, 312, 1, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 197
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofHQaXKNW8d3"
      },
      "source": [
        "def preprocessing(features_df,Model2):\n",
        "\n",
        "  X_test = np.array(features_df['mfccs'].tolist())\n",
        "  result= []\n",
        "\n",
        "  for i in tqdm(range(len(X_test))):\n",
        "    for j in range(X_test.shape[1]):\n",
        "      a = Model2.predict(X_test[i][j].reshape(1,-1))\n",
        "      result.append(a[0])\n",
        "  \n",
        "  res = np.array(result)\n",
        "  result_dict = {}\n",
        "\n",
        "  for i in range(res.shape[0]):\n",
        "    arr = res[i]\n",
        "    index = np.where(arr == np.amax(arr))[0][0]\n",
        "\n",
        "    if index == 0:\n",
        "      result_dict[i] = \"music\"\n",
        "    elif index == 1:\n",
        "      result_dict[i] = \"silence\"\n",
        "    else:\n",
        "      result_dict[i] = \"speech\"\n",
        "  \n",
        "  #window_length_time = window_length/Fs\n",
        "  tempar = ['music','speech']\n",
        "  arr = []\n",
        "\n",
        "  for id in result_dict:\n",
        "    if result_dict[id] in tempar:\n",
        "      arr.append(id)\n",
        "  \n",
        "  for item in arr:\n",
        "    if (item + 3) < len(result_dict):\n",
        "      if result_dict[item] == result_dict[item+2]:\n",
        "        result_dict[item+1] = result_dict[item]\n",
        "  return result_dict"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBZbO0GFtptt"
      },
      "source": [
        "n_frames = 313"
      ],
      "execution_count": 211,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwbbXtQaYm4l"
      },
      "source": [
        "def predictf(result_dict):\n",
        "  count_dict = {'music':0,\n",
        "              'speech':0}\n",
        "\n",
        "  predictions = []\n",
        "  threshold = 70\n",
        "  cntMusic = 0\n",
        "  cntSpeech = 0\n",
        "\n",
        "  for id in result_dict:\n",
        "\n",
        "    if id == (len(result_dict) - 1):\n",
        "      if cntMusic >= threshold:\n",
        "        count_dict['music'] = 1\n",
        "      if cntSpeech >= threshold:\n",
        "        count_dict['speech'] = 1\n",
        "\n",
        "\n",
        "      predictions.append([count_dict['music'],count_dict['speech']])\n",
        "      break\n",
        "\n",
        "\n",
        "    \n",
        "    if id % n_frames == 0:\n",
        "      if id == 0:\n",
        "        continue\n",
        "      if cntMusic >= threshold:\n",
        "        count_dict['music'] = 1\n",
        "      if cntSpeech >= threshold:\n",
        "        count_dict['speech'] = 1\n",
        "\n",
        "\n",
        "      predictions.append([count_dict['music'],count_dict['speech']])\n",
        "\n",
        "      cntMusic = 0\n",
        "      cntSpeech = 0\n",
        "      \n",
        "      count_dict['music'] = 0\n",
        "      count_dict['speech'] = 0\n",
        "      continue\n",
        "    if result_dict[id] == 'music':\n",
        "      cntMusic +=1\n",
        "    elif result_dict[id] == 'speech':\n",
        "      cntSpeech += 1\n",
        "    else:\n",
        "      continue\n",
        "\n",
        "  df = pd.DataFrame(predictions,columns=['music','speech'])\n",
        "  return df"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WJ2eMFDuHuo"
      },
      "source": [
        "feat = extract_mfcc_spects(root)"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dkBt4YQYua2h",
        "outputId": "13cca9f1-f90a-46a3-f36d-8f43537213a1"
      },
      "source": [
        "r = preprocessing(feat,Model2)"
      ],
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|| 30/30 [07:30<00:00, 15.00s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpcuTrD_O6Un"
      },
      "source": [
        "df = predictf(r)"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU06vv5Nu7DR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Pnz95L9Rt3TR",
        "outputId": "19d5f9cf-603a-4acd-9d2b-272d8951548b"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>music</th>\n",
              "      <th>speech</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   music  speech\n",
              "0      0       1\n",
              "1      1       1\n",
              "2      0       1\n",
              "3      0       1\n",
              "4      1       1"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WJfTA4lwk4U"
      },
      "source": [
        "df['files'] = os.listdir(root)"
      ],
      "execution_count": 220,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BFXGZ_t7wq5J",
        "outputId": "951a6939-fda8-4378-c071-a7e87a77e2e5"
      },
      "source": [
        "df.tail()"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>music</th>\n",
              "      <th>speech</th>\n",
              "      <th>files</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>music+speech_noisy6.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>S001.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>S003.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>music+speech_noisy5.npy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>S004.npy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    music  speech                    files\n",
              "25      0       1  music+speech_noisy6.npy\n",
              "26      0       1                 S001.npy\n",
              "27      1       1                 S003.npy\n",
              "28      0       1  music+speech_noisy5.npy\n",
              "29      0       1                 S004.npy"
            ]
          },
          "metadata": {},
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RnfPGKYUtTrt",
        "outputId": "a21bcf52-86f9-490a-8411-3f9ecbdea477"
      },
      "source": [
        ""
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 215
        }
      ]
    }
  ]
}